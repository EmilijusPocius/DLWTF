{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmilijusPocius/DLWTF/blob/main/TNLP_RecipeGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDTYWYkNoP0S"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IMPORTAI"
      ],
      "metadata": {
        "id": "x84OMB8dpn-N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd-_cFDrJOuC"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install -q diffusers transformers accelerate\n",
        "\n",
        "import pandas\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import files\n",
        "import kagglehub\n",
        "import math\n",
        "import os\n",
        "import gdown\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from IPython.display import display, Markdown, clear_output\n",
        "import ipywidgets as widgets\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DUOMEN≈≤ IR MODELIO ATSISIUNTIMAS"
      ],
      "metadata": {
        "id": "AzvjqDYkppfE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWBAs0kUk--G"
      },
      "outputs": [],
      "source": [
        "print(\"Atsisiunƒçiamas RecipeNLG duomen≈≥ rinkinys...\")\n",
        "path = kagglehub.dataset_download(\"paultimothymooney/recipenlg\")\n",
        "csv_path = os.path.join(path, \"RecipeNLG_dataset.csv\")\n",
        "print(f\"Duomen≈≥ path: {csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = '1GVRMOc4rObbTiu7tU6FdjVCgQzX-3V5q'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "output = 'recipe_model_transformer_version_finalest_final.keras'\n",
        "\n",
        "if not os.path.exists(output):\n",
        "    print(f\"Atsisiunƒçiamas modelis...\")\n",
        "    gdown.download(url, output, quiet=False)\n",
        "else:\n",
        "    print(\"Modelio failas jau yra.\")"
      ],
      "metadata": {
        "id": "dvhsszhapmcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PARAMETRAI"
      ],
      "metadata": {
        "id": "Wim-AMeQnJkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 15000\n",
        "TOKENIZER_SAMPLE_SIZE = 300000\n",
        "MAX_ENCODER_LEN = 25\n",
        "MAX_DECODER_LEN = 100\n",
        "BATCH_SIZE = 256\n",
        "EMBED_DIM = 128\n",
        "NUM_HEADS = 4\n",
        "FF_DIM = 512\n",
        "DROPOUT_RATE = 0.1\n",
        "EPOCHS = 15\n",
        "DATA_LIMIT = 300000"
      ],
      "metadata": {
        "id": "o3aA0XtNHFvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TOKENIZARTORIAI"
      ],
      "metadata": {
        "id": "jy6yPzm18H4Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97huqrnRmXmI"
      },
      "outputs": [],
      "source": [
        "# Tokenizatorius\n",
        "print(f\"Skaitoma {TOKENIZER_SAMPLE_SIZE} ƒØra≈°≈≥ imtis tokenizatoriaus apmokymui...\")\n",
        "df_sample = pandas.read_csv(csv_path, nrows=TOKENIZER_SAMPLE_SIZE)\n",
        "\n",
        "# Paruo≈°iame tekstƒÖ\n",
        "df_sample = df_sample.dropna(subset=['NER', 'directions'])\n",
        "df_sample['input_text'] = df_sample['NER'].apply(lambda x: ' '.join(eval(x)))\n",
        "df_sample['target_text'] = df_sample['directions'].apply(lambda x: '<start> ' + ' '.join(eval(x)) + ' <end>')\n",
        "\n",
        "# Encoder Tokenizer\n",
        "print(\"Apmokomas Encoder Tokenizer...\")\n",
        "encoder_tokenizer = keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<unk>\")\n",
        "encoder_tokenizer.fit_on_texts(df_sample['input_text'])\n",
        "\n",
        "# Decoder Tokenizer\n",
        "print(\"Apmokomas Decoder Tokenizer...\")\n",
        "decoder_tokenizer = keras.preprocessing.text.Tokenizer(\n",
        "    num_words=VOCAB_SIZE,\n",
        "    oov_token=\"<unk>\",\n",
        "    filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        ")\n",
        "decoder_tokenizer.fit_on_texts(df_sample['target_text'])\n",
        "\n",
        "del df_sample\n",
        "\n",
        "print(\"Tokenizatoriai paruo≈°ti.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRENIRAVIMO DUOMEN≈≤ GENERAVIMAS"
      ],
      "metadata": {
        "id": "l9vmePIF8Me5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfZ9_91BkGXE"
      },
      "outputs": [],
      "source": [
        "class RecipeDataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, df, batch_size, encoder_tokenizer, decoder_tokenizer,\n",
        "                 max_encoder_len, max_decoder_len, shuffle=True, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.df = df\n",
        "        self.batch_size = batch_size\n",
        "        self.encoder_tokenizer = encoder_tokenizer\n",
        "        self.decoder_tokenizer = decoder_tokenizer\n",
        "        self.max_encoder_len = max_encoder_len\n",
        "        self.max_decoder_len = max_decoder_len\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = self.df.index.tolist()\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Nurodome kiek batch≈≥ vienoje epochoje\n",
        "        return int(np.floor(len(self.df) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Generuojame vienƒÖ batchƒÖ duomen≈≥\n",
        "        start_index = index * self.batch_size\n",
        "        end_index = (index + 1) * self.batch_size\n",
        "        batch_indexes = self.indexes[start_index:end_index]\n",
        "\n",
        "        # Paimame duomenis pagal indeksus\n",
        "        df_batch = self.df.loc[batch_indexes]\n",
        "\n",
        "        # Paruo≈°iame duomenis\n",
        "        encoder_input = self._prepare_encoder_input(df_batch['input_text'].tolist())\n",
        "        decoder_input, decoder_output = self._prepare_decoder_io(df_batch['target_text'].tolist())\n",
        "\n",
        "        return (encoder_input, decoder_input), decoder_output\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Sumai≈°ome indeksus po kiekvienos epochos\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def _prepare_encoder_input(self, texts):\n",
        "        return keras.preprocessing.sequence.pad_sequences(\n",
        "            self.encoder_tokenizer.texts_to_sequences(texts),\n",
        "            maxlen=self.max_encoder_len, padding='post'\n",
        "        )\n",
        "\n",
        "    def _prepare_decoder_io(self, texts):\n",
        "        decoder_input_seq = keras.preprocessing.sequence.pad_sequences(\n",
        "            self.decoder_tokenizer.texts_to_sequences(texts),\n",
        "            maxlen=self.max_decoder_len, padding='post'\n",
        "        )\n",
        "\n",
        "        decoder_output_seq = np.zeros_like(decoder_input_seq)\n",
        "        decoder_output_seq[:, :-1] = decoder_input_seq[:, 1:]\n",
        "\n",
        "        return decoder_input_seq, decoder_output_seq\n",
        "\n",
        "print(\"RecipeDataGenerator klasƒó sukurta.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DUOMEN≈≤ PARUO≈†IMAS (PALEISTI JEI BUS TRENIRUOJAMAS MODELIS)"
      ],
      "metadata": {
        "id": "a68uUwnW78yy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVEh2PP2kKjd"
      },
      "outputs": [],
      "source": [
        "# print(\"ƒÆkeliamas duomen≈≥ rinkinys\")\n",
        "# df_full = pandas.read_csv(csv_path, usecols=['NER', 'directions'])\n",
        "# df_full = df_full.dropna().reset_index(drop=True)\n",
        "# df_full = df_full.iloc[:DATA_LIMIT]\n",
        "\n",
        "# print(\"Ruo≈°iamas tekstas...\")\n",
        "# df_full['input_text'] = df_full['NER'].progress_apply(lambda x: ' '.join(eval(x)))\n",
        "# df_full['target_text'] = df_full['directions'].progress_apply(lambda x: '<start> ' + ' '.join(eval(x)) + ' <end>')\n",
        "\n",
        "# df_full.drop(columns=['NER', 'directions'], inplace=True)\n",
        "\n",
        "# print(\"Duomenys dalijami ƒØ treniravimo ir validacijos aibes...\")\n",
        "# train_df, val_df = train_test_split(df_full, test_size=0.1, random_state=42)\n",
        "\n",
        "# del df_full\n",
        "\n",
        "# print(f\"Treniravimo aibƒós dydis: {len(train_df)}\")\n",
        "# print(f\"Validacijos aibƒós dydis: {len(val_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_generator = RecipeDataGenerator(\n",
        "#     df=train_df,\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     encoder_tokenizer=encoder_tokenizer,\n",
        "#     decoder_tokenizer=decoder_tokenizer,\n",
        "#     max_encoder_len=MAX_ENCODER_LEN,\n",
        "#     max_decoder_len=MAX_DECODER_LEN\n",
        "# )\n",
        "\n",
        "# val_generator = RecipeDataGenerator(\n",
        "#     df=val_df,\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     encoder_tokenizer=encoder_tokenizer,\n",
        "#     decoder_tokenizer=decoder_tokenizer,\n",
        "#     max_encoder_len=MAX_ENCODER_LEN,\n",
        "#     max_decoder_len=MAX_DECODER_LEN,\n",
        "#     shuffle=False\n",
        "# )\n",
        "\n",
        "# print(\"Duomen≈≥ generatoriai paruo≈°ti.\")"
      ],
      "metadata": {
        "id": "a54DDfMESn0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CUSTOM TRANSFORMERIS"
      ],
      "metadata": {
        "id": "ZPZp5b2z8TBB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_oyftErJf0n"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(keras.layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = keras.layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim, mask_zero=True\n",
        "        )\n",
        "        self.position_embeddings = keras.layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return self.token_embeddings.compute_mask(inputs, mask=mask)\n",
        "\n",
        "class TransformerEncoder(keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential([\n",
        "            keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
        "            keras.layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm_1 = keras.layers.LayerNormalization()\n",
        "        self.layernorm_2 = keras.layers.LayerNormalization()\n",
        "        self.dropout = keras.layers.Dropout(DROPOUT_RATE)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = tf.cast(mask, dtype=\"int32\")\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "\n",
        "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        proj_output = self.dropout(proj_output)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "class TransformerDecoder(keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential([\n",
        "            keras.layers.Dense(dense_dim, activation=\"relu\"),\n",
        "            keras.layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm_1 = keras.layers.LayerNormalization()\n",
        "        self.layernorm_2 = keras.layers.LayerNormalization()\n",
        "        self.layernorm_3 = keras.layers.LayerNormalization()\n",
        "        self.dropout = keras.layers.Dropout(DROPOUT_RATE)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = tf.cast(mask, dtype=\"int32\")\n",
        "            padding_mask = mask[:, tf.newaxis, :]\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1, value=encoder_outputs, key=encoder_outputs, attention_mask=padding_mask\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        proj_output = self.dropout(proj_output)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6UPvqpGnrj4"
      },
      "source": [
        "#MODELIO SUK≈™RIMAS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(MAX_ENCODER_LEN, VOCAB_SIZE, EMBED_DIM)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(EMBED_DIM, FF_DIM, NUM_HEADS)(x)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "x_dec = PositionalEmbedding(MAX_DECODER_LEN, VOCAB_SIZE, EMBED_DIM)(decoder_inputs)\n",
        "x_dec = TransformerDecoder(EMBED_DIM, FF_DIM, NUM_HEADS)(x_dec, encoder_outputs)\n",
        "\n",
        "decoder_outputs = keras.layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x_dec)\n",
        "\n",
        "transformer_model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer_recipe_generator\")\n",
        "\n",
        "transformer_model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "transformer_model.summary()"
      ],
      "metadata": {
        "id": "ChOjluSzdVo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnUhz1A3nvgp"
      },
      "source": [
        "#MODELIO U≈ΩKROVIMAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1lvowcPnw34"
      },
      "outputs": [],
      "source": [
        "model_path = 'recipe_model_transformer_version_finalest_final.keras'\n",
        "\n",
        "print(f\"Loading weights into model from: {model_path}\")\n",
        "\n",
        "loaded_model = transformer_model\n",
        "loaded_model.load_weights(model_path)\n",
        "loaded_model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODELIO TRENIRAVIMAS (PALEISTI JEI REIKIA)"
      ],
      "metadata": {
        "id": "jn3QFIJUQkBi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdEcZOQAJhXN"
      },
      "outputs": [],
      "source": [
        "# early_stopping = keras.callbacks.EarlyStopping(\n",
        "#     monitor='val_loss', patience=2, restore_best_weights=True\n",
        "# )\n",
        "# checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "#     'transformer_recipe_model.keras', save_best_only=True\n",
        "# )\n",
        "\n",
        "# history = transformer_model.fit(\n",
        "#     train_generator,\n",
        "#     validation_data=val_generator,\n",
        "#     epochs=EPOCHS,\n",
        "#     callbacks=[early_stopping, checkpoint]\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GENERAVIMO PARUO≈†IMAS"
      ],
      "metadata": {
        "id": "EKqUakYlnCDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API KEY\n",
        "try:\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "except:\n",
        "    print(\"Failed to fetch API KEY.\")\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "text_model_name = 'gemini-2.0-flash'\n",
        "text_model = genai.GenerativeModel(text_model_name)\n",
        "\n",
        "image_model_name = \"runwayml/stable-diffusion-v1-5\"\n",
        "\n",
        "# Check for GPU availability\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available. Using torch.float16 and enabling model CPU offload.\")\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        image_model_name,\n",
        "        torch_dtype=torch.float16\n",
        "    )\n",
        "    pipe.enable_model_cpu_offload()\n",
        "else:\n",
        "    print(\"GPU is NOT available. Using torch.float32 for CPU execution. Image generation will be very slow.\")\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        image_model_name,\n",
        "        torch_dtype=torch.float32 # Use float32 for CPU\n",
        "    )\n",
        "\n",
        "pipe.enable_attention_slicing()\n",
        "\n",
        "print(\"Modeliai paruo≈°ti.\")"
      ],
      "metadata": {
        "id": "EbKLQsZqb3fs",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX-VeMpNJj8x"
      },
      "outputs": [],
      "source": [
        "def generate_recipe_transformer(input_text, max_len=100, temperature=0.7):\n",
        "    # Paruo≈°iame ingredientus (Encoder input)\n",
        "    input_seq = encoder_tokenizer.texts_to_sequences([input_text])\n",
        "    input_seq = keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=MAX_ENCODER_LEN, padding='post')\n",
        "    input_tensor = tf.convert_to_tensor(input_seq)\n",
        "\n",
        "    # Pradedame instrukcijƒÖ (Decoder input)\n",
        "    start_token = decoder_tokenizer.word_index['<start>']\n",
        "    end_token = decoder_tokenizer.word_index['<end>']\n",
        "\n",
        "    output_seq = [start_token]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        target_seq = tf.convert_to_tensor([output_seq])\n",
        "\n",
        "        predictions = transformer_model.predict([input_tensor, target_seq], verbose=0)\n",
        "\n",
        "        predictions = predictions[0, -1, :]\n",
        "\n",
        "        # Temperature Sampling\n",
        "        predictions = np.log(predictions + 1e-10) / temperature\n",
        "        exp_preds = np.exp(predictions)\n",
        "        predictions = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        # I≈°renkame kitƒÖ ≈æodƒØ\n",
        "        predicted_id = np.random.choice(len(predictions), p=predictions)\n",
        "\n",
        "        if predicted_id == end_token:\n",
        "            break\n",
        "\n",
        "        output_seq.append(predicted_id)\n",
        "\n",
        "    # Konvertuojame skaiƒçius atgal ƒØ tekstƒÖ\n",
        "    recipe_text = decoder_tokenizer.sequences_to_texts([output_seq])[0]\n",
        "\n",
        "    # I≈°valome <start>\n",
        "    recipe_text = recipe_text.replace('<start>', '').strip()\n",
        "\n",
        "    return recipe_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_recipe(original_ingredients, raw_instructions):\n",
        "    prompt = f\"\"\"\n",
        "    You are a professional chef editor. Refine this raw AI-generated recipe.\n",
        "\n",
        "    1. CREATE A NAME: Give it a creative, appetizing name.\n",
        "    2. INGREDIENTS: The input list has no quantities. Add logical quantities (e.g., '200g pasta' instead of just 'pasta').\n",
        "       - If essential items (salt, oil, water, pepper) are missing, add them and mark as \"(Suggested)\".\n",
        "    3. INSTRUCTIONS: Rewrite the raw instructions to be clear, numbered steps. Fix grammar. Do NOT change the dish, just the clarity.\n",
        "\n",
        "    Input Ingredients: {original_ingredients}\n",
        "    Raw AI Instructions: {raw_instructions}\n",
        "\n",
        "    Output Format (Markdown):\n",
        "    # [Name]\n",
        "    **Description:** [One sentence summary]\n",
        "    ## Ingredients\n",
        "    * ...\n",
        "    ## Instructions\n",
        "    1. ...\n",
        "    \"\"\"\n",
        "\n",
        "    safety_settings = [\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\"\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "            \"threshold\": \"BLOCK_NONE\"\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "            \"threshold\": \"BLOCK_NONE\"\n",
        "        },\n",
        "        {\n",
        "            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "            \"threshold\": \"BLOCK_NONE\"\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Siunƒçiame u≈æklausƒÖ su saugumo nustatymais\n",
        "        response = text_model.generate_content(prompt, safety_settings=safety_settings)\n",
        "\n",
        "        # Patikriname, ar gavome atsakymƒÖ\n",
        "        if response.text:\n",
        "            return response.text\n",
        "        else:\n",
        "            return \"Modelis sugeneravo tu≈°ƒçiƒÖ atsakymƒÖ (galb≈´t dƒól turinio filtro).\"\n",
        "\n",
        "    except Exception as e:\n",
        "        # Jei kyla klaida, parodome jƒÖ ekrane vietoje recepto\n",
        "        return f\"**Klaida apdorojant receptƒÖ:** {str(e)}\\n\\nPatikrinkite API raktƒÖ arba 'Raw Output'.\"\n"
      ],
      "metadata": {
        "id": "tKJ_BNHNaIWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image(ingredients, recipe_text):\n",
        "    # I≈°traukiame pavadinimƒÖ paveikslƒóliui\n",
        "    match = re.search(r'# (.*?)\\n', recipe_text)\n",
        "    if match:\n",
        "        recipe_title = match.group(1).strip()\n",
        "    else:\n",
        "        recipe_title = \"Delicious food dish\" # Default\n",
        "\n",
        "    image_prompt = (\n",
        "        f\"professional food photography of {recipe_title}, \"\n",
        "        f\"containing {ingredients}, \"\n",
        "        \"studio lighting, delicious, 4k, high resolution, michelin star presentation\"\n",
        "    )\n",
        "\n",
        "    image = pipe(image_prompt).images[0]\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "7WmyvlqLTdN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recipes(ingredients, temperature=0.7, count=1, generate_img=False):\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i in range(count):\n",
        "        raw_text = generate_recipe_transformer(ingredients, temperature=temperature)\n",
        "        refined_recipe = enhance_recipe(ingredients, raw_text)\n",
        "\n",
        "        image = None\n",
        "        if generate_img:\n",
        "            try:\n",
        "                if \"Nepavyko\" in refined_recipe:\n",
        "                     image_prompt_text = f\"delicious {ingredients} dish, professional food photography\"\n",
        "                else:\n",
        "                     image_prompt_text = refined_recipe\n",
        "                image = generate_image(ingredients, image_prompt_text)\n",
        "            except Exception as e:\n",
        "                print(f\"Nuotraukos generavimo klaida: {e}\")\n",
        "\n",
        "        results.append({\n",
        "            \"raw\": raw_text,\n",
        "            \"refined\": refined_recipe,\n",
        "            \"image\": image\n",
        "        })\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "qffAOs-kJtCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RECEPTO GENERAVIMAS"
      ],
      "metadata": {
        "id": "1bMEjJjtTWQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown, clear_output\n",
        "\n",
        "# -- UI Elementai --\n",
        "ingredients_input = widgets.Text(\n",
        "    value='beef tomato potato pasta spices',\n",
        "    placeholder='ƒÆveskite ingredientus...',\n",
        "    description='Ingredientai:',\n",
        "    layout=widgets.Layout(width='600px'),\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "temp_slider = widgets.FloatSlider(\n",
        "    value=0.8,\n",
        "    min=0.1,\n",
        "    max=1.5,\n",
        "    step=0.1,\n",
        "    description='K≈´rybi≈°kumas:',\n",
        "    readout=True,\n",
        "    readout_format='.1f',\n",
        "    layout=widgets.Layout(width='600px'),\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "count_slider = widgets.IntSlider(\n",
        "    value=1,\n",
        "    min=1,\n",
        "    max=3,\n",
        "    step=1,\n",
        "    description='Recept≈≥ kiekis:',\n",
        "    readout=True,\n",
        "    layout=widgets.Layout(width='600px'),\n",
        "    style={'description_width': 'initial'}\n",
        ")\n",
        "\n",
        "# Checkbox nuotraukoms\n",
        "image_checkbox = widgets.Checkbox(\n",
        "    value=False,\n",
        "    description='Generuoti nuotraukƒÖ?',\n",
        "    disabled=False,\n",
        "    indent=False,\n",
        "    layout=widgets.Layout(width='600px')\n",
        ")\n",
        "\n",
        "run_button = widgets.Button(\n",
        "    description='Generuoti',\n",
        "    button_style='success',\n",
        "    layout=widgets.Layout(width='200px', margin='10px 0 0 0'),\n",
        "    icon='check'\n",
        ")\n",
        "\n",
        "out = widgets.Output()\n",
        "\n",
        "def on_button_click(b):\n",
        "    run_button.disabled = True\n",
        "    run_button.description = \"Dirbama...\"\n",
        "\n",
        "    with out:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # Paimame reik≈°mes\n",
        "        ing = ingredients_input.value\n",
        "        temp = temp_slider.value\n",
        "        cnt = count_slider.value\n",
        "        do_img = image_checkbox.value\n",
        "\n",
        "        status_msg = \"‚è≥ Generatorius cookina\"\n",
        "        if do_img:\n",
        "            status_msg += \" ir fotografuoja patiekalƒÖ.\"\n",
        "\n",
        "        print(status_msg)\n",
        "\n",
        "        try:\n",
        "            results_list = generate_recipes(ing, temperature=temp, count=cnt, generate_img=do_img)\n",
        "\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            if not results_list:\n",
        "                print(\"Klaida: Nieko nesugeneruota.\")\n",
        "\n",
        "            for idx, res in enumerate(results_list):\n",
        "                display(Markdown(f\"---\"))\n",
        "                display(Markdown(f\"## üçΩÔ∏è Receptas #{idx + 1}\"))\n",
        "\n",
        "                # 1. Nuotrauka\n",
        "                if res.get('image'):\n",
        "                    display(res['image'])\n",
        "                elif do_img:\n",
        "                    print(\"Nepavyko sugeneruoti nuotraukƒÖ.\")\n",
        "\n",
        "                # 2. I≈°manus (Refined) Receptas\n",
        "                refined_text = str(res.get('refined', ''))\n",
        "\n",
        "                if refined_text and len(refined_text) > 10:\n",
        "                    try:\n",
        "                        display(Markdown(refined_text))\n",
        "                    except:\n",
        "                        print(refined_text)\n",
        "                else:\n",
        "                    print(\"Nepavyko pagerinti recepto.\")\n",
        "\n",
        "                # 3. ≈Ωalias (Raw) tekstas\n",
        "                raw_text = str(res.get('raw', ''))\n",
        "                if raw_text:\n",
        "                    display(Markdown(f\"---\"))\n",
        "                    display(Markdown(f\"**Transformerio sugeneruotas tekstas (Raw):**\"))\n",
        "                    display(Markdown(f\"> *{raw_text}*\"))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"KLAIDA: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "        finally:\n",
        "            run_button.disabled = False\n",
        "            run_button.description = \"Generuoti\"\n",
        "\n",
        "run_button.on_click(on_button_click)\n",
        "\n",
        "# UI I≈°dƒóstymas\n",
        "ui = widgets.VBox([\n",
        "    widgets.HTML(\"<h2>PotatoGPT ü•î</h2>\"),\n",
        "    ingredients_input,\n",
        "    temp_slider,\n",
        "    count_slider,\n",
        "    image_checkbox,\n",
        "    run_button,\n",
        "    out\n",
        "], layout=widgets.Layout(align_items='center', width='100%'))\n",
        "\n",
        "display(ui)"
      ],
      "metadata": {
        "id": "T0Wh_fZ23i3_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}